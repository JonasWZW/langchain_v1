# -*- coding:utf-8 -*-



"""
记忆是一个能够存储关于先前交互信息的系统。对于 AI 代理来说，记忆至关重要，因为它能让它们记住先前的交互，从反馈中学习，并适应用户偏好。
随着代理处理更复杂的任务和大量用户交互，这种能力对于效率和用户满意度都变得不可或缺。

短期记忆使您的应用程序能够在单个线程或对话中记住先前的交互。

对话历史是最常见的短期记忆形式。长对话对当今的 LLMs 构成挑战；完整的历史可能无法适应 LLM 的上下文窗口，导致上下文丢失或错误。

即使您的模型支持完整上下文长度，大多数 LLMs 在长上下文中仍然表现不佳。它们会被过时或离题的内容“分心”，同时还会遭受响应时间变慢和成本更高的困扰。

聊天模型通过消息接受上下文，这些消息包括指令（系统消息）和输入（人类消息）。
在聊天应用中，消息在人类输入和模型响应之间交替，导致消息列表随着时间的推移而增长。
由于上下文窗口有限，许多应用可以从使用删除或“遗忘”过时信息的技术中受益。

"""

